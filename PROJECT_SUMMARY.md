# Medical RAG Chatbot - Project Summary

## ğŸ“‹ Project Overview

**Type**: Retrieval-Augmented Generation (RAG) Medical Q&A System  
**Status**: âœ… Complete and Ready to Use  
**Location**: `C:\Users\hp\OneDrive\Desktop\vit\medical-rag-chatbot\`

## ğŸ¯ What This System Does

A production-ready medical chatbot that:
- Answers medical questions with **citation-backed responses**
- Uses **RAG (Retrieval-Augmented Generation)** to ground answers in your dataset
- Provides **source references** for every claim
- Includes **medical disclaimers** and safety warnings
- Supports multiple document formats (PDF, TXT, CSV, JSON)
- Offers both **web UI** (Gradio) and **REST API** (FastAPI)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query: "What are the symptoms of diabetes?"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RETRIEVAL PHASE                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚ Query        â”‚ â†’ Embed â†’ Search FAISS Vector Store       â”‚
â”‚  â”‚ Embedding    â”‚           (finds top-5 relevant chunks)   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ [Retrieved Context with Sources]
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GENERATION PHASE                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  Prompt Template:                        â”‚               â”‚
â”‚  â”‚  - System: "You are a medical assistant" â”‚               â”‚
â”‚  â”‚  - Context: [Source 1] ... [Source 5]   â”‚               â”‚
â”‚  â”‚  - Query: User's question                â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                     â–¼                                        â”‚
â”‚           OpenAI GPT-4o-mini                                â”‚
â”‚                     â”‚                                        â”‚
â”‚                     â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Answer with [Source X] citations         â”‚               â”‚
â”‚  â”‚ + Medical disclaimer                     â”‚               â”‚
â”‚  â”‚ + Safety warnings (if applicable)        â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
medical-rag-chatbot/
â”œâ”€â”€ ğŸ“„ README.md                 # Comprehensive documentation
â”œâ”€â”€ ğŸ“„ QUICKSTART.md             # 5-minute setup guide
â”œâ”€â”€ ğŸ“„ LICENSE                   # MIT license + medical disclaimer
â”œâ”€â”€ ğŸ“„ setup.ps1                 # Automated setup script (Windows)
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ“„ .env.example              # Environment template
â”œâ”€â”€ ğŸ“„ .gitignore                # Git ignore rules
â”œâ”€â”€ ğŸ³ Dockerfile                # Container definition
â”œâ”€â”€ ğŸ³ docker-compose.yml        # Docker orchestration
â”‚
â”œâ”€â”€ ğŸ“‚ src/                      # Source code
â”‚   â”œâ”€â”€ config.py                # Configuration & settings
â”‚   â”œâ”€â”€ ingest.py                # Document ingestion & indexing
â”‚   â”œâ”€â”€ retriever.py             # FAISS semantic search
â”‚   â”œâ”€â”€ llm.py                   # OpenAI LLM wrapper
â”‚   â”œâ”€â”€ rag.py                   # Main RAG orchestration
â”‚   â”œâ”€â”€ app_api.py               # FastAPI REST API
â”‚   â””â”€â”€ app_gradio.py            # Gradio web UI
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw/                     # Your medical documents (add here)
â”‚   â””â”€â”€ vector_store/            # FAISS index (auto-generated)
â”‚
â””â”€â”€ ğŸ“‚ tests/
    â””â”€â”€ test_rag.py              # Unit tests
```

## ğŸš€ Quick Start (3 Commands)

```powershell
# 1. Run automated setup
.\setup.ps1

# 2. Add your OpenAI key to .env
notepad .env

# 3. Run ingestion & launch UI
python src\ingest.py
python src\app_gradio.py
```

Then open http://localhost:7860 and start chatting!

## ğŸ”‘ Key Features Implemented

### 1. **Multi-Format Document Ingestion**
- âœ… PDF support (with page tracking)
- âœ… Plain text files
- âœ… CSV (auto-detects content column)
- âœ… JSON (handles nested structures)
- âœ… Sample data fallback for quick demos

### 2. **Smart Chunking**
- âœ… Recursive character splitting (1000 chars, 200 overlap)
- âœ… Preserves metadata (source, page, category)
- âœ… Configurable chunk sizes

### 3. **Vector Store (FAISS)**
- âœ… Local file-based storage
- âœ… Fast similarity search
- âœ… Persistent index
- âœ… Batch processing for large datasets

### 4. **LLM Integration**
- âœ… OpenAI GPT-4o-mini (configurable)
- âœ… Custom system prompts for medical context
- âœ… Temperature control (0.1 for accuracy)
- âœ… Token limit management

### 5. **Citation System**
- âœ… Every answer includes [Source X] references
- âœ… Source metadata (file, page, category)
- âœ… Snippet preview of source content
- âœ… Configurable top-K retrieval

### 6. **Safety Features**
- âœ… Emergency detection (chest pain, can't breathe, etc.)
- âœ… Personal advice warnings (medication, dosage)
- âœ… Medical disclaimer on every response
- âœ… Out-of-scope query handling

### 7. **User Interfaces**
- âœ… **Gradio Web UI**: Chat interface with source display
- âœ… **FastAPI REST API**: Programmatic access with OpenAPI docs
- âœ… **CLI**: Terminal-based interaction
- âœ… CORS enabled for frontend integration

### 8. **Production Ready**
- âœ… Docker support
- âœ… Health check endpoints
- âœ… Comprehensive error handling
- âœ… Environment-based configuration
- âœ… Unit tests with pytest
- âœ… Logging and monitoring hooks

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Language** | Python 3.11+ | Core implementation |
| **LLM** | OpenAI GPT-4o-mini | Answer generation |
| **Embeddings** | OpenAI text-embedding-3-small | Semantic search |
| **Vector Store** | FAISS | Document indexing & retrieval |
| **Framework** | LangChain | RAG orchestration |
| **API** | FastAPI | REST endpoints |
| **UI** | Gradio | Web chat interface |
| **Container** | Docker | Deployment |
| **Testing** | pytest | Unit tests |

## ğŸ“¦ Dependencies Installed

- `openai==1.54.0` - OpenAI API client
- `langchain==0.3.7` - RAG framework
- `faiss-cpu==1.8.0` - Vector similarity search
- `fastapi==0.115.4` - Web API framework
- `gradio==4.44.1` - Web UI
- `pypdf==4.3.1` - PDF processing
- `pandas==2.2.3` - CSV handling
- Plus 10+ supporting libraries

## ğŸ”§ Configuration Options

All settings in `src/config.py` (can override via `.env`):

```python
# LLM Settings
LLM_MODEL = "gpt-4o-mini"           # or "gpt-4o", "gpt-3.5-turbo"
EMBEDDING_MODEL = "text-embedding-3-small"
TEMPERATURE = 0.1                    # Lower = more deterministic
MAX_TOKENS = 1000

# RAG Settings
CHUNK_SIZE = 1000                    # Characters per chunk
CHUNK_OVERLAP = 200                  # Overlap for context
TOP_K = 5                            # Sources to retrieve

# Server Ports
API_PORT = 8000                      # FastAPI
GRADIO_PORT = 7860                   # Gradio UI
```

## ğŸ¨ Usage Examples

### Web UI (Gradio)
```powershell
python src\app_gradio.py
# Open http://localhost:7860
# Type: "What are the symptoms of diabetes?"
```

### REST API (FastAPI)
```powershell
python src\app_api.py
# POST to http://localhost:8000/chat
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"query": "What is hypertension?"}'
```

### Command Line
```powershell
python src\rag.py
# Interactive: Type questions, get answers with sources
```

## ğŸ“Š Adding Your Dataset

### Step 1: Prepare Files
Place your medical documents in `data/raw/`:
```powershell
Copy-Item "C:\path\to\your\dataset\*" data\raw\
```

### Step 2: Supported Formats

**PDF**: Automatically extracts text and tracks page numbers
**TXT**: Plain text files (markdown OK)
**CSV**: Must have 'text', 'content', or 'description' column
**JSON**: List of objects with 'text'/'content' field

### Step 3: Re-Index
```powershell
python src\ingest.py
```

### Step 4: Restart App
```powershell
python src\app_gradio.py
```

## ğŸ§ª Testing

Run all tests:
```powershell
pytest tests/ -v
```

Test individual components:
```powershell
python src\retriever.py  # Test retrieval
python src\llm.py        # Test LLM
python src\rag.py        # Test end-to-end
```

## ğŸ³ Docker Deployment

### Quick Docker Run
```powershell
docker build -t medical-rag-chatbot .
docker run -p 7860:7860 -p 8000:8000 --env-file .env medical-rag-chatbot
```

### Docker Compose (Recommended)
```powershell
docker-compose up
```

Access:
- Gradio: http://localhost:7860
- API: http://localhost:8000/docs

## ğŸ” Security Notes

- âœ… API keys stored in `.env` (not committed to git)
- âœ… CORS enabled (configure origins for production)
- âš ï¸ Add authentication for production use
- âš ï¸ If handling PHI, ensure HIPAA compliance
- âš ï¸ Rate limiting recommended for public APIs

## ğŸš€ Production Checklist

Before deploying to production:

- [ ] Replace sample data with your medical dataset
- [ ] Add authentication (JWT tokens)
- [ ] Configure CORS with specific origins
- [ ] Add rate limiting
- [ ] Set up monitoring (logs, metrics)
- [ ] Use managed vector DB (Pinecone/Weaviate) for scale
- [ ] Add Redis caching for frequent queries
- [ ] Implement audit logging
- [ ] Review medical disclaimers with legal team
- [ ] Test with real users
- [ ] Set up CI/CD pipeline

## ğŸ“ˆ Future Enhancements

Ideas for extending the system:

1. **Hybrid Search**: Combine keyword + semantic search
2. **Query Rewriting**: Improve retrieval with question expansion
3. **Re-ranking**: Use cross-encoder for better source selection
4. **Feedback Loop**: Collect user ratings to improve responses
5. **Fine-tuning**: Train embeddings on medical terminology
6. **Multi-language**: Support non-English queries
7. **Voice Interface**: Add speech-to-text input
8. **Admin Dashboard**: Manage documents, view analytics
9. **A/B Testing**: Compare different retrieval strategies
10. **Explainability**: Show why sources were selected

## ğŸ“š Documentation

- **README.md**: Full documentation (architecture, API, deployment)
- **QUICKSTART.md**: 5-minute setup guide
- **This file**: Project summary and overview
- **Code comments**: Inline documentation in all modules
- **API docs**: Auto-generated at http://localhost:8000/docs

## ğŸ†˜ Troubleshooting

Common issues and solutions:

**"No OpenAI API key"**
â†’ Edit `.env` and add `OPENAI_API_KEY=sk-...`

**"No vector store found"**
â†’ Run `python src\ingest.py` first

**"Module not found"**
â†’ Activate venv: `.\venv\Scripts\Activate.ps1`

**"Rate limit exceeded"**
â†’ Reduce batch size in `ingest.py` or wait and retry

**Poor answer quality**
â†’ Increase `TOP_K`, use `gpt-4o`, improve dataset

## ğŸ“ Learning Resources

To understand RAG better:
- LangChain docs: https://python.langchain.com/
- OpenAI embeddings guide: https://platform.openai.com/docs/guides/embeddings
- FAISS wiki: https://github.com/facebookresearch/faiss/wiki
- RAG paper: https://arxiv.org/abs/2005.11401

## âœ… What's Complete

All 9 todo items completed:
1. âœ… Requirements clarified (OpenAI, FAISS, Gradio+API)
2. âœ… Dataset handling (sample data + custom support)
3. âœ… Architecture designed (RAG pipeline documented)
4. âœ… Project scaffolded (all files created)
5. âœ… Ingestion implemented (multi-format, chunking, FAISS)
6. âœ… RAG system built (retrieval + LLM + citations)
7. âœ… Testing added (safety checks, unit tests)
8. âœ… Docker configured (Dockerfile, compose, README)
9. âœ… Setup automated (setup.ps1, QUICKSTART.md)

## ğŸ‰ Ready to Use!

Your Medical RAG Chatbot is fully built and ready to go. Just add your OpenAI API key and optionally your dataset.

**Next steps**:
1. Run `.\setup.ps1` for guided setup
2. Or follow `QUICKSTART.md` for manual setup
3. Add your dataset to `data/raw/`
4. Run `python src\ingest.py`
5. Launch `python src\app_gradio.py`

**Need help?** Review the comprehensive `README.md` or inspect the code comments.

---

Built with â¤ï¸ for medical education and information access.

**Remember**: Always consult healthcare professionals for medical advice!
